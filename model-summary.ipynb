{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMG(\n",
      "  (self_attn): ModuleList(\n",
      "    (0): MultiHeadAttention(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (cross_attn): ModuleList(\n",
      "    (0): MultiHeadAttention(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (cross_attn_rel): ModuleList(\n",
      "    (0): MultiHeadAttention(\n",
      "      (attention): ScaledDotProductAttention(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (gcn_2ds): ModuleList(\n",
      "    (0): GraphEdgeAttenNetwork(\n",
      "      (index_get): Gen_Index()\n",
      "      (index_aggr): Aggre_Index()\n",
      "      (edgeatten): MultiHeadedEdgeAttention(\n",
      "        (nn_edge): Sequential(\n",
      "          (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        )\n",
      "        (nn): mySequential(\n",
      "          (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (proj_edge): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (proj_query): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (proj_value): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (prop): Sequential(\n",
      "        (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (gcn_3ds): ModuleList(\n",
      "    (0): GraphEdgeAttenNetwork(\n",
      "      (index_get): Gen_Index()\n",
      "      (index_aggr): Aggre_Index()\n",
      "      (edgeatten): MultiHeadedEdgeAttention(\n",
      "        (nn_edge): Sequential(\n",
      "          (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        )\n",
      "        (nn): mySequential(\n",
      "          (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (proj_edge): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (proj_query): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (proj_value): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (prop): Sequential(\n",
      "        (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_attn_fc): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (6): Linear(in_features=32, out_features=8, bias=True)\n",
      "  )\n",
      "  (drop_out): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import os\n",
    "from src.utils.config import Config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.model.model_utils.network_MMG import MMG\n",
    "from src.model.model_utils.network_util import (MLP, Aggre_Index, Gen_Index,\n",
    "                                                build_mlp)\n",
    "from src.model.transformer.attention import MultiHeadAttention\n",
    "\n",
    "# !pip install torchsummary\n",
    "# !pip install torchinfo\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "class GraphEdgeAttenNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_heads, dim_node, dim_edge, dim_atten, aggr= 'max', use_bn=False,\n",
    "                 flow='target_to_source',attention = 'fat',use_edge:bool=True, **kwargs):\n",
    "        super().__init__() #  \"Max\" aggregation.\n",
    "        self.name = 'edgeatten'\n",
    "        self.dim_node=dim_node\n",
    "        self.dim_edge=dim_edge\n",
    "        self.index_get = Gen_Index(flow=flow)\n",
    "        if attention == 'fat':        \n",
    "            self.index_aggr = Aggre_Index(aggr=aggr,flow=flow)\n",
    "        elif attention == 'distance':\n",
    "            aggr = 'add'\n",
    "            self.index_aggr = Aggre_Index(aggr=aggr,flow=flow)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        self.edgeatten = MultiHeadedEdgeAttention(\n",
    "            dim_node=dim_node,dim_edge=dim_edge,dim_atten=dim_atten,\n",
    "            num_heads=num_heads,use_bn=use_bn,attention=attention,use_edge=use_edge, **kwargs)\n",
    "        self.prop = build_mlp([dim_node+dim_atten, dim_node+dim_atten, dim_node],\n",
    "                            do_bn= use_bn, on_last=False)\n",
    "\n",
    "    def forward(self, x, edge_feature, edge_index, weight=None, istrain=False):\n",
    "        assert x.ndim == 2\n",
    "        assert edge_feature.ndim == 2\n",
    "        x_i, x_j = self.index_get(x, edge_index)\n",
    "        xx, gcn_edge_feature, prob = self.edgeatten(x_i, edge_feature, x_j, weight, istrain=istrain)\n",
    "        xx = self.index_aggr(xx, edge_index, dim_size = x.shape[0])\n",
    "        xx = self.prop(torch.cat([x,xx],dim=1))\n",
    "        return xx, gcn_edge_feature\n",
    "  \n",
    "\n",
    "class MultiHeadedEdgeAttention(torch.nn.Module):\n",
    "    def __init__(self, num_heads: int, dim_node: int, dim_edge: int, dim_atten: int, use_bn=False,\n",
    "                 attention = 'fat', use_edge:bool = True, **kwargs):\n",
    "        super().__init__()\n",
    "        assert dim_node % num_heads == 0\n",
    "        assert dim_edge % num_heads == 0\n",
    "        assert dim_atten % num_heads == 0\n",
    "        self.name = 'MultiHeadedEdgeAttention'\n",
    "        self.dim_node=dim_node\n",
    "        self.dim_edge=dim_edge\n",
    "        self.d_n = d_n = dim_node // num_heads\n",
    "        self.d_e = d_e = dim_edge // num_heads\n",
    "        self.d_o = d_o = dim_atten // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.use_edge = use_edge\n",
    "        self.nn_edge = build_mlp([dim_node*2+dim_edge,(dim_node+dim_edge),dim_edge],\n",
    "                          do_bn= use_bn, on_last=False)\n",
    "        self.mask_obj = 0.5\n",
    "        \n",
    "        DROP_OUT_ATTEN = None\n",
    "        if 'DROP_OUT_ATTEN' in kwargs:\n",
    "            DROP_OUT_ATTEN = kwargs['DROP_OUT_ATTEN']\n",
    "            # print('drop out in',self.name,'with value',DROP_OUT_ATTEN)\n",
    "        \n",
    "        self.attention = attention\n",
    "        assert self.attention in ['fat']\n",
    "        \n",
    "        if self.attention == 'fat':\n",
    "            if use_edge:\n",
    "                self.nn = MLP([d_n+d_e, d_n+d_e, d_o],do_bn=use_bn,drop_out = DROP_OUT_ATTEN)\n",
    "            else:\n",
    "                self.nn = MLP([d_n, d_n*2, d_o],do_bn=use_bn,drop_out = DROP_OUT_ATTEN)\n",
    "                \n",
    "            self.proj_edge  = build_mlp([dim_edge,dim_edge])\n",
    "            self.proj_query = build_mlp([dim_node,dim_node])\n",
    "            self.proj_value = build_mlp([dim_node,dim_atten])\n",
    "        elif self.attention == 'distance':\n",
    "            self.proj_value = build_mlp([dim_node,dim_atten])\n",
    "\n",
    "        \n",
    "    def forward(self, query, edge, value, weight=None, istrain=False):\n",
    "        batch_dim = query.size(0)\n",
    "        \n",
    "        edge_feature = torch.cat([query, edge, value],dim=1)\n",
    "        # avoid overfitting by mask relation input object feature\n",
    "        # if random.random() < self.mask_obj and istrain: \n",
    "        #     feat_mask = torch.cat([torch.ones_like(query),torch.zeros_like(edge), torch.ones_like(value)],dim=1)\n",
    "        #     edge_feature = torch.where(feat_mask == 1, edge_feature, torch.zeros_like(edge_feature))\n",
    "        \n",
    "        edge_feature = self.nn_edge( edge_feature )#.view(b, -1, 1)\n",
    "\n",
    "        if self.attention == 'fat':\n",
    "            value = self.proj_value(value)\n",
    "            query = self.proj_query(query).view(batch_dim, self.d_n, self.num_heads)\n",
    "            edge = self.proj_edge(edge).view(batch_dim, self.d_e, self.num_heads)\n",
    "            if self.use_edge:\n",
    "                prob = self.nn(torch.cat([query,edge],dim=1)) # b, dim, head    \n",
    "            else:\n",
    "                prob = self.nn(query) # b, dim, head \n",
    "            prob = prob.softmax(1)\n",
    "            x = torch.einsum('bm,bm->bm', prob.reshape_as(value), value)\n",
    "        \n",
    "        elif self.attention == 'distance':\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError('')\n",
    "        \n",
    "        return x, edge_feature, prob\n",
    "    \n",
    "    \n",
    "class MMG(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_node, dim_edge, dim_atten, num_heads=1, aggr= 'max', \n",
    "                 use_bn=False,flow='target_to_source', attention = 'fat', \n",
    "                 hidden_size=512, depth=1, use_edge:bool=True, **kwargs,\n",
    "                 ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = depth\n",
    "\n",
    "        self.self_attn = nn.ModuleList(\n",
    "            MultiHeadAttention(d_model=dim_node, d_k=dim_node // num_heads, d_v=dim_node // num_heads, h=num_heads) for i in range(depth))\n",
    "\n",
    "        self.cross_attn = nn.ModuleList(\n",
    "            MultiHeadAttention(d_model=dim_node, d_k=dim_node // num_heads, d_v=dim_node // num_heads, h=num_heads) for i in range(depth))\n",
    "\n",
    "        self.cross_attn_rel = nn.ModuleList(\n",
    "            MultiHeadAttention(d_model=dim_edge, d_k=dim_edge // num_heads, d_v=dim_edge // num_heads, h=num_heads) for i in range(depth))\n",
    "        \n",
    "        self.gcn_2ds = torch.nn.ModuleList()\n",
    "        self.gcn_3ds = torch.nn.ModuleList()\n",
    "        \n",
    "        for _ in range(self.depth):\n",
    "\n",
    "            self.gcn_2ds.append(GraphEdgeAttenNetwork(\n",
    "                            num_heads,\n",
    "                            dim_node,\n",
    "                            dim_edge,\n",
    "                            dim_atten,\n",
    "                            aggr,\n",
    "                            use_bn=use_bn,\n",
    "                            flow=flow,\n",
    "                            attention=attention,\n",
    "                            use_edge=use_edge, \n",
    "                            **kwargs))\n",
    "            \n",
    "            self.gcn_3ds.append(GraphEdgeAttenNetwork(\n",
    "                            num_heads,\n",
    "                            dim_node,\n",
    "                            dim_edge,\n",
    "                            dim_atten,\n",
    "                            aggr,\n",
    "                            use_bn=use_bn,\n",
    "                            flow=flow,\n",
    "                            attention=attention,\n",
    "                            use_edge=use_edge, \n",
    "                            **kwargs))\n",
    "           \n",
    "        self.self_attn_fc = nn.Sequential(  # 11 32 32 4(head)\n",
    "            nn.Linear(4, 32),  # xyz, dist\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.Linear(32, num_heads)\n",
    "        )\n",
    "        \n",
    "        self.drop_out = torch.nn.Dropout(kwargs['DROP_OUT_ATTEN'])\n",
    "    \n",
    "    \n",
    "    def forward(self, obj_feature_3d, obj_feature_2d, edge_feature_3d, edge_feature_2d, edge_index, batch_ids, obj_center=None, discriptor=None, istrain=False):\n",
    "\n",
    "        # compute weight for obj\n",
    "        if obj_center is not None:\n",
    "            # get attention weight for object\n",
    "            batch_size = batch_ids.max().item() + 1\n",
    "            N_K = obj_feature_3d.shape[0]\n",
    "            obj_mask = torch.zeros(1, 1, N_K, N_K).cuda()\n",
    "            obj_distance_weight = torch.zeros(1, self.num_heads, N_K, N_K).cuda()\n",
    "            count = 0\n",
    "\n",
    "            for i in range(batch_size):\n",
    "\n",
    "                idx_i = torch.where(batch_ids == i)[0]\n",
    "                obj_mask[:, :, count:count + len(idx_i), count:count + len(idx_i)] = 1\n",
    "            \n",
    "                center_A = obj_center[None, idx_i, :].clone().detach().repeat(len(idx_i), 1, 1)\n",
    "                center_B = obj_center[idx_i, None, :].clone().detach().repeat(1, len(idx_i), 1)\n",
    "                center_dist = (center_A - center_B)\n",
    "                dist = center_dist.pow(2)\n",
    "                dist = torch.sqrt(torch.sum(dist, dim=-1))[:, :, None]\n",
    "                weights = torch.cat([center_dist, dist], dim=-1).unsqueeze(0)  # 1 N N 4\n",
    "                dist_weights = self.self_attn_fc(weights).permute(0,3,1,2)  # 1 num_heads N N\n",
    "                \n",
    "                attention_matrix_way = 'add'\n",
    "                obj_distance_weight[:, :, count:count + len(idx_i), count:count + len(idx_i)] = dist_weights\n",
    "\n",
    "                count += len(idx_i)\n",
    "        else:\n",
    "            obj_mask = None\n",
    "            obj_distance = None\n",
    "            attention_matrix_way = 'mul'\n",
    "           \n",
    "        for i in range(self.depth):\n",
    "            \n",
    "\n",
    "            for i in range(self.depth):\n",
    "\n",
    "                obj_feature_3d = obj_feature_3d.unsqueeze(0)\n",
    "                obj_feature_2d = obj_feature_2d.unsqueeze(0)\n",
    "                \n",
    "                obj_feature_3d = self.self_attn[i](obj_feature_3d, obj_feature_3d, obj_feature_3d, attention_weights=obj_distance_weight, way=attention_matrix_way, attention_mask=obj_mask, use_knn=False)\n",
    "                obj_feature_2d = self.cross_attn[i](obj_feature_2d, obj_feature_3d, obj_feature_3d, attention_weights=obj_distance_weight, way=attention_matrix_way, attention_mask=obj_mask, use_knn=False)\n",
    "                \n",
    "                obj_feature_3d = obj_feature_3d.squeeze(0)\n",
    "                obj_feature_2d = obj_feature_2d.squeeze(0)  \n",
    "\n",
    "\n",
    "                obj_feature_3d, edge_feature_3d = self.gcn_3ds[i](obj_feature_3d, edge_feature_3d, edge_index, istrain=istrain)\n",
    "                obj_feature_2d, edge_feature_2d = self.gcn_2ds[i](obj_feature_2d, edge_feature_2d, edge_index, istrain=istrain)\n",
    "\n",
    "                \n",
    "                edge_feature_2d = edge_feature_2d.unsqueeze(0)\n",
    "                edge_feature_3d = edge_feature_3d.unsqueeze(0)\n",
    "                \n",
    "                edge_feature_2d = self.cross_attn_rel[i](edge_feature_2d, edge_feature_3d, edge_feature_3d, use_knn=False)\n",
    "                \n",
    "                edge_feature_2d = edge_feature_2d.squeeze(0)\n",
    "                edge_feature_3d = edge_feature_3d.squeeze(0)\n",
    "\n",
    "                if i < (self.depth-1) or self.depth==1:\n",
    "                    \n",
    "                    obj_feature_3d = F.relu(obj_feature_3d)\n",
    "                    obj_feature_3d = self.drop_out(obj_feature_3d)\n",
    "                    \n",
    "                    obj_feature_2d = F.relu(obj_feature_2d)\n",
    "                    obj_feature_2d = self.drop_out(obj_feature_2d)\n",
    "\n",
    "                    edge_feature_3d = F.relu(edge_feature_3d)\n",
    "                    edge_feature_3d = self.drop_out(edge_feature_3d)\n",
    "\n",
    "                    edge_feature_2d = F.relu(edge_feature_2d)\n",
    "                    edge_feature_2d = self.drop_out(edge_feature_2d)\n",
    "        \n",
    "            \n",
    "            return obj_feature_3d, obj_feature_2d, edge_feature_3d, edge_feature_2d\n",
    "        \n",
    "from torchinfo import summary\n",
    "\n",
    "dim_node = 512         \n",
    "dim_edge = 512      \n",
    "dim_atten = 256 \n",
    "num_heads = 8  \n",
    "drop_out_atten = 0.1 \n",
    "\n",
    "model = MMG(dim_node, dim_edge, dim_atten, num_heads, DROP_OUT_ATTEN=drop_out_atten)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/vlsat/lib/python3.8/site-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/vlsat/lib/python3.8/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[0;32mIn[54], line 196\u001b[0m, in \u001b[0;36mMMG.forward\u001b[0;34m(self, obj_feature_3d, obj_feature_2d, edge_feature_3d, edge_feature_2d, edge_index, batch_ids, obj_center, discriptor, istrain)\u001b[0m\n\u001b[1;32m    194\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    198\u001b[0m     idx_i \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(batch_ids \u001b[38;5;241m==\u001b[39m i)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 206\u001b[0m\n\u001b[1;32m    202\u001b[0m drop_out_atten \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \n\u001b[1;32m    204\u001b[0m model \u001b[38;5;241m=\u001b[39m MMG(dim_node, dim_edge, dim_atten, num_heads, DROP_OUT_ATTEN\u001b[38;5;241m=\u001b[39mdrop_out_atten)\n\u001b[0;32m--> 206\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_point_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 객체 포인트 클라우드 데이터\u001b[39;49;00m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_2d_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 객체의 2D 특성 데이터\u001b[39;49;00m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_label_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 객체 레이블\u001b[39;49;00m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrel_label_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 관계 레이블\u001b[39;49;00m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 관계의 엣지 인덱스\u001b[39;49;00m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# 객체 또는 관계의 추가적인 설명자 정보\u001b[39;49;00m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 배치 내 각 데이터 포인트의 배치 ID\u001b[39;49;00m\n\u001b[1;32m    214\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# 만약 모델이 추가적인 입력을 요구한다면, input_data 리스트에 해당 더미 데이터를 추가합니다.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# 예: summary(model, input_data=[obj_point_list, obj_2d_feats, 추가 입력1, 추가 입력2, ...])\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/vlsat/lib/python3.8/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/vlsat/lib/python3.8/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlsat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
